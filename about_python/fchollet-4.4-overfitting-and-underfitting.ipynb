{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/soon/workspace/python/ml_basic/about_python\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../img/overfitting_hunkim.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../img/overfitting_hunkim.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overfitting, under fitting\n",
    "- over fitting\n",
    " : Training 데이터 셋 안에서는 정말 정확히 동작하는데 다른 데이터에 대해서는 엉뚱한 동작을 하게 되는 것\n",
    "\n",
    "참고\n",
    "![asdfasdf](../img/overfitting_hunkim.png)\n",
    "\n",
    "위 그림에서 보듯이 두번째 그림에는 너무 training data에 맞춰서 선이 구부러져 있는데, 이렇게 도출된 모델은 다른 데이터가 들어왔을때 똑같은 모델이 되리라는 보장을 할 수 없다. 즉, 일반화에서 멀어진 현상을 이야기함.\n",
    "\n",
    "## 여기서는 overfitting을\n",
    "- Reducing the network's size  \n",
    "network의 사이즈를 줄여나가는 방식  \n",
    "- weight regularization  \n",
    "가중치가 일정 범위안에서만 존재하도록 제한하는 방식  \n",
    "- adding dropout  \n",
    "랜덤하게 0을 대입하는 방식...  \n",
    "을 수행해서 overfitting을 줄여나간다.\n",
    "\n",
    "## Reducing the network's size\n",
    "network 갯수를 줄이는 것이다.  \n",
    "결론적으로 쉽게 이야기하면, layer의 수를 얼마나 잡을지를 결정할 수 있는 함수는 없다. 따라서 직접 돌려보면서 network의 사이즈를 줄이거나 늘려야 한다는 이야기를 하려고 하는데 그 근거와 예를 들기 위해 길게 설명합니다. \n",
    "\n",
    "딥러닝에서는 학습 가능한 파라미터들의 갯수를 'capacity'라고 부른다. 직관적으로, 하나의 모델에 더 많은 parameter들이 더 많은 'memorization capacity'를 가지게 되고 그럼으로 인해서 training sample과 대상간에 dictionary와 같은 형태의 매핑형태로 쉽게 배울 수 있다.  \n",
    "  \n",
    "하지만 네트워크의 memorization resource들을 제한적으로 가지고있다면 mapping을 쉽게 배울 수 없는데, 이런 것으로 인해 loss를 줄이기 위해 target에 대한 예측력을 가진 압축된 representation을 학습해야 한다.이 압축된 representation을 정확하게 우리가 관심을 가지는 representation의 유형이라고 하네요...  \n",
    "  \n",
    "아쉽게도 마법과 같은 함수가 없는 없다고 함. 올바른 수의 layer가 무엇인지 또는 각 layer의 크기가 적절한지를 결정하는 마법과 같은 공식은 없다. 데이터에 맞는 모델 크기를 찾으려면 다양한 아키텍처의 배열을 검증해야 한다.(test set이 아닌 validation set에서)  \n",
    "  \n",
    "적절한 모델의 크기를 찾는 일반적인 워크 플로우는 **비교적 적은수의 레이어**와 **적은 수의 매개변수**로 시작해서 validation loss과 관련하여 **return이 줄어드는 것(unitil you see diminishing returns)을 볼때까지** layer의 크기를 늘리거나 새 layer를 추가하는 것이다.  \n",
    "  \n",
    "머신러닝과의 비교: http://pythonkim.tistory.com/42 [파이쿵]  \n",
    "머신러닝에서는 training data를 늘리거나, feature의 갯수를 줄이거나, dropout을 사용한다. feature의 갯수를 줄일때, 여기서 설명하는 것처럼 sigmoid, relu의 방식을 설명하는데, 더 좋은 방법은 dropout이라고 함.     \n",
    "  \n",
    "예제)  \n",
    "network의 사이즈를 지정하고 train data와 test data에 대한 validation 데이터를 얻어내는 예제  \n",
    "```code\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "## model 세팅(layer, activation 등)\n",
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "original_model.add(layers.Dense(16, activation='relu'))\n",
    "original_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "## 얻어낸 original_model의 activiation과 layer 정보를 통해 loss를 binary_crossentropy방식으로 컴파일\n",
    "original_model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "\n",
    "## original_hist :: 실제 계산 (학습데이터, 테스트 데이터를 통해 validation_loss등을 계산)\n",
    "original_hist = original_model.fit(x_train, y_train,epochs=20,batch_size=512,validation_data=(x_test, y_test))\n",
    "\n",
    "## 계산한 validation_loss를 얻어낸다.\n",
    "epochs = range(1, 21)\n",
    "original_val_loss = original_hist.history['val_loss']\n",
    "\n",
    "## 그래프에 표현\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "## weight regularization\n",
    "overfitting을 완화하는 일반적인 방법은 가중치(cost가 작은 값을 가지도록 만들어서 네트워크의 complexity 에 제한점을 두는 것(to put constraints)이다. 이렇게 하면 가중치값의 분포를 조금 더 regular, 즉 정규화할수 있다. 이러한 방식을 가중치 정규화라 한다. \n",
    "  \n",
    "keras에서는 아래와 같이 두가지의 가중치를 구하는 방식이 있다.    \n",
    "- L1 regularization :  \n",
    "    여기서 추가된 cost는 가중치 상관계수의 절대값에 비례한다.  \n",
    "- L2 regularization :  \n",
    "    여기서 추가된 cost는 가중치의 상관계수의 제곱에 피례한다. (예를 들어 가중치의 L2 norm 이라고 불린다.)  \n",
    "    L2 regularization은 신경 네트워크의 맥락에서(in the context of neural networks), 체중 감량(weight decay)라고도 한다.  \n",
    "\n",
    "예제)\n",
    "아래와 같이 kernel_regularizer라는 keyword argument의 value로 regularizers.l2(number)를 대입하는 것으로 간단히 해결되는 듯하다.    \n",
    "```code\n",
    "from keras import regularizers\n",
    "\n",
    "l2_model = models.Sequential()\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(10000,)))\n",
    "l2_model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "l2_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "```\n",
    "\n",
    "## weight regularization in keras\n",
    "케라스에서는 weight_regularizer 인스턴스들을 keyword argument로 전달 가능하다.\n",
    "아래의 코드는 movie review classification network 에 L2 weight rgularization을 더하는 코드다.\n",
    "ex)\n",
    "```code\n",
    "from keras import regularizers\n",
    "\n",
    "l2_model = models.Sequential()\n",
    "\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu', input_shape=(10000,)))\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "```\n",
    "regularization에 대한 쉬운 설명 참고\n",
    "http://pythonkim.tistory.com/23 [파이쿵]\n",
    "\n",
    "\n",
    "\n",
    "**12(0.001)의 의미**\n",
    "l2 (0.001)는 계층의 가중치 행렬에 있는 모든 상관계수가 0.001 * weight_coefficient_value를 네트워크의 전체 손실에 더한다는 것. 주의할 것은 이런 페널티는 오직 training time에만 더할 수 있기 때문에, 이 network의 loss는 test time에서의 loss보다 training time에서의 loss가 훨씬 커진다.\n",
    "\n",
    "## Adding dropout\n",
    "- 신경망 네트워크에서 흔히 쓰이는 정규화 방법(regularization techniques)중의 하나.  \n",
    "토론토 대학의 Hinton과 그의 학생들의 노가다로 구해졌다고 함.  \n",
    "- 계층에 적용되는 dropout은, training time 동안 layer의 다수의 output feature들을 \"dropout\"(0으로 세팅)으로 구성한다고 함.  \n",
    "- 의역) 즉, training time동안 layer의 다수의 output feature들을 0으로 세팅하는데 이렇게 0으로 세팅하는 것을 drop out이라 함.\n",
    "- 예를 들면 \\[0.2, 0.5, 1.3, 0.8, 1.1\\] 을 \\[0, 0.5, 1.3, 0, 1.1\\]로 바꿔줌\n",
    "- **\"드롭아웃비율(dropout rate)\"**\n",
    "zero-out 되는 feature들의 비율(the fraction of being zeroed-out)이다.  \n",
    "(미안합니다. 요건 구글 번역입니다.) 일반적으로 0.2와 0.5 사이에 설정됩니다. 테스트 시간에는 단위가 제거되지 않고 레이어의 출력 값이 드롭 아웃 비율과 같은 비율로 축소되므로 교육 시간보다 더 많은 단위가 활성화되어 있다는 사실에 균형을 맞출 수 있습니다.  \n",
    "  \n",
    "Numpy 행렬이 layer의 output인 layer_output을 포함하고 있다고 가정하자. 학습 시간(training time)에 우리는 무작위로 행렬(matrix)의 값의 일부를 zero-out할 것이다.  \n",
    "  \n",
    "```code\n",
    "layer_output *= np.randint(0, high=2. size=layer_output.shape)\n",
    "```\n",
    "```code\n",
    "low : int  \n",
    "    Lowest(singned) integer to be drawn from the distribution  \n",
    "high : int, optimal\n",
    "    If provided, one above the largest (signed) integer to be drawn from the distribution  \n",
    "```\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "# https://s3.amazonaws.com/text-datasets/imdb.npz에서 데이터 다운로드\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequence(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 데이타(train_data, test_data)는 x변수(x_train, x_test)\n",
    "# 각 label들은 y변수(y_train, y_test)\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequence(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequence(test_data)\n",
    "\n",
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing the network's size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "original_model.add(layers.Dense(16, activation='relu'))\n",
    "original_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "original_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 것을 작은 네트워크로 바꿔보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_model = models.Sequential()\n",
    "smaller_model.add(layers.Dense(4, activation='relu', input_shape=(10000,)))\n",
    "smaller_model.add(layers.Dense(4, activation='relu'))\n",
    "smaller_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "smaller_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## original network와 smaller network간의 validation loss를 비교해본다.  \n",
    "**original_hist**에는 original network를  \n",
    "**smaller_model_hist**에는 smaller network를 담는다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 11s 446us/step - loss: 0.4709 - acc: 0.8208 - val_loss: 0.3465 - val_acc: 0.8810\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 10s 411us/step - loss: 0.2653 - acc: 0.9098 - val_loss: 0.2951 - val_acc: 0.8846\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 7s 272us/step - loss: 0.2054 - acc: 0.9256 - val_loss: 0.2783 - val_acc: 0.8900\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 7s 267us/step - loss: 0.1701 - acc: 0.9400 - val_loss: 0.2921 - val_acc: 0.8849\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 6s 248us/step - loss: 0.1449 - acc: 0.9494 - val_loss: 0.3064 - val_acc: 0.8806\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 6s 248us/step - loss: 0.1279 - acc: 0.9560 - val_loss: 0.3457 - val_acc: 0.8723\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 6s 248us/step - loss: 0.1148 - acc: 0.9610 - val_loss: 0.3837 - val_acc: 0.8656\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 6s 257us/step - loss: 0.1004 - acc: 0.9653 - val_loss: 0.3857 - val_acc: 0.8683\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 6s 236us/step - loss: 0.0916 - acc: 0.9683 - val_loss: 0.4116 - val_acc: 0.8640\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 6s 253us/step - loss: 0.0800 - acc: 0.9736 - val_loss: 0.4441 - val_acc: 0.8617\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 6s 246us/step - loss: 0.0723 - acc: 0.9768 - val_loss: 0.4542 - val_acc: 0.8640\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 6s 224us/step - loss: 0.0658 - acc: 0.9781 - val_loss: 0.4889 - val_acc: 0.8609\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 7s 288us/step - loss: 0.0547 - acc: 0.9830 - val_loss: 0.5431 - val_acc: 0.8566\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 5s 210us/step - loss: 0.0511 - acc: 0.9839 - val_loss: 0.5951 - val_acc: 0.8474\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 6s 258us/step - loss: 0.0418 - acc: 0.9878 - val_loss: 0.5962 - val_acc: 0.8546\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 5s 218us/step - loss: 0.0394 - acc: 0.9886 - val_loss: 0.6390 - val_acc: 0.8505\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 6s 256us/step - loss: 0.0332 - acc: 0.9904 - val_loss: 0.6455 - val_acc: 0.8543\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 6s 254us/step - loss: 0.0291 - acc: 0.9915 - val_loss: 0.6788 - val_acc: 0.8529\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 6s 240us/step - loss: 0.0247 - acc: 0.9936 - val_loss: 0.7263 - val_acc: 0.8484\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 6s 229us/step - loss: 0.0237 - acc: 0.9929 - val_loss: 0.7511 - val_acc: 0.8506\n"
     ]
    }
   ],
   "source": [
    "original_hist = original_model.fit(x_train, y_train, epochs=20, batch_size=512, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "각 epoch마다 굉장히 오래 걸린다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 10s 403us/step - loss: 0.5605 - acc: 0.8101 - val_loss: 0.4690 - val_acc: 0.8594\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 8s 330us/step - loss: 0.3872 - acc: 0.8851 - val_loss: 0.3679 - val_acc: 0.8758\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 5s 209us/step - loss: 0.2976 - acc: 0.9064 - val_loss: 0.3150 - val_acc: 0.8858\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 6s 236us/step - loss: 0.2457 - acc: 0.9192 - val_loss: 0.2907 - val_acc: 0.8896\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 6s 243us/step - loss: 0.2122 - acc: 0.9278 - val_loss: 0.2803 - val_acc: 0.8902\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 5s 186us/step - loss: 0.1887 - acc: 0.9346 - val_loss: 0.2780 - val_acc: 0.8906\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 5s 204us/step - loss: 0.1713 - acc: 0.9408 - val_loss: 0.2798 - val_acc: 0.8887\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 5s 216us/step - loss: 0.1566 - acc: 0.9472 - val_loss: 0.2849 - val_acc: 0.8862\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 5s 189us/step - loss: 0.1438 - acc: 0.9520 - val_loss: 0.2944 - val_acc: 0.8844\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 5s 194us/step - loss: 0.1329 - acc: 0.9556 - val_loss: 0.3155 - val_acc: 0.8775\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 6s 227us/step - loss: 0.1236 - acc: 0.9595 - val_loss: 0.3160 - val_acc: 0.8797\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 7s 279us/step - loss: 0.1150 - acc: 0.9628 - val_loss: 0.3248 - val_acc: 0.8792\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 5s 198us/step - loss: 0.1073 - acc: 0.9654 - val_loss: 0.3396 - val_acc: 0.8762\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 4s 174us/step - loss: 0.1000 - acc: 0.9682 - val_loss: 0.3638 - val_acc: 0.8704\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 5s 184us/step - loss: 0.0939 - acc: 0.9711 - val_loss: 0.3708 - val_acc: 0.8710\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 5s 211us/step - loss: 0.0882 - acc: 0.9724 - val_loss: 0.3839 - val_acc: 0.8698\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 5s 196us/step - loss: 0.0822 - acc: 0.9758 - val_loss: 0.4022 - val_acc: 0.8669\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 5s 216us/step - loss: 0.0771 - acc: 0.9778 - val_loss: 0.4157 - val_acc: 0.8670\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 5s 186us/step - loss: 0.0724 - acc: 0.9791 - val_loss: 0.4354 - val_acc: 0.8643\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 5s 190us/step - loss: 0.0676 - acc: 0.9805 - val_loss: 0.4666 - val_acc: 0.8603\n"
     ]
    }
   ],
   "source": [
    "smaller_model_hist = smaller_model.fit(x_train, y_train, epochs=20, batch_size=512, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1,21)\n",
    "original_val_loss = original_hist.history['val_loss']\n",
    "smaller_model_val_loss = smaller_model_hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA2RL2RvAQwAEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f16cc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# b+ is for 'blue cross'\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "# \"bo\" is for 'blue dot'\n",
    "plt.plot(epochs, smaller_model_val_loss, 'bo', label='Smaller model')\n",
    "plt.xlabel('Epochs') # running step...\n",
    "plt.ylabel('Validation loss') # Validation 손실\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```code\n",
    "+ : Original model\n",
    ". : Smaller model\n",
    "```\n",
    "4에서 6사이에서 smaller network가 overfitting을 하기 시작하고  \n",
    "이것(validation loss)의 성능(performance)은 overfitting을 시작하면서부터 현저하게 느려진다.  \n",
    "  \n",
    "Now, for kicks, 벤치마크에 문제가 허용하는 것보다 훨씬 많은 용량을 가진 네트워크를 추가해보면 아래와 같다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_model = models.Sequential()\n",
    "bigger_model.add(layers.Dense(512, activation='relu', input_shape=(10000,)))\n",
    "bigger_model.add(layers.Dense(512, activation='relu'))\n",
    "bigger_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bigger_model의 loss를 'binary_crossentropy'로 compile 하고, bigger_model_hist에 fit 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4668 - acc: 0.7938 - val_loss: 0.3724 - val_acc: 0.8298\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 34s 1ms/step - loss: 0.2220 - acc: 0.9119 - val_loss: 0.2870 - val_acc: 0.8853\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.1292 - acc: 0.9523 - val_loss: 0.3339 - val_acc: 0.8822\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.0677 - acc: 0.9815 - val_loss: 0.4298 - val_acc: 0.8829\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 31s 1ms/step - loss: 0.0399 - acc: 0.9892 - val_loss: 0.5364 - val_acc: 0.8808\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.0534 - acc: 0.9888 - val_loss: 0.5685 - val_acc: 0.8826\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.0732 - acc: 0.9915 - val_loss: 0.8411 - val_acc: 0.8545\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 25s 1ms/step - loss: 0.0029 - acc: 0.9994 - val_loss: 1.6622 - val_acc: 0.7484\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.0255 - acc: 0.9939 - val_loss: 0.6777 - val_acc: 0.8805\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 25s 1ms/step - loss: 1.4167e-04 - acc: 1.0000 - val_loss: 2.3167 - val_acc: 0.7376\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.0770 - acc: 0.9901 - val_loss: 0.6840 - val_acc: 0.8760\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.0480 - acc: 0.9911 - val_loss: 0.6824 - val_acc: 0.8762\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 3.8093e-04 - acc: 1.0000 - val_loss: 0.7705 - val_acc: 0.8773\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.0559 - acc: 0.9920 - val_loss: 0.8277 - val_acc: 0.8710\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.0073 - acc: 0.9987 - val_loss: 2.2676 - val_acc: 0.7278\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.0144 - acc: 0.9974 - val_loss: 0.8503 - val_acc: 0.8733\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 8.1309e-05 - acc: 1.0000 - val_loss: 0.8786 - val_acc: 0.8761\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.0490 - acc: 0.9937 - val_loss: 0.8477 - val_acc: 0.8716\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.0184 - acc: 0.9968 - val_loss: 1.4765 - val_acc: 0.8177\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.8793 - val_acc: 0.8718\n"
     ]
    }
   ],
   "source": [
    "bigger_model_hist = bigger_model.fit(x_train, y_train, epochs=20, batch_size=512, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## binary_crossentropy로 컴파일한 bigger_model_hist의 loss(손실)만을 따로 담은후, 그래프로 표현해보면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10add3cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bigger_model_val_loss = bigger_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, bigger_model_val_loss, 'bo', label='Bigger model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림을 보면 overfitting을 거의 one epoch(거의 1)부터 시작하는 것을 볼수 있다. validation loss가 굉장이 노이즈가 많이 낀것으로 보임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지의 정리를 해보면 우리는 overfitting을 줄이기 위한 방법들 세가지  \n",
    "(네트워크 사이즈 줄이기,가중치 정규화, 네트워크 사이즈 줄이기)중에 **네트워크의 사이즈 줄이기**를 하고 있고, bigger model의 overfitting이 굉장히 크다는 것을 확인 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두 네트워크의 training loss (학습손실)을 아래에 표시해보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aecfc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_train_loss = original_hist.history['loss']\n",
    "bigger_model_train_loss = bigger_model_hist.history['loss']\n",
    "\n",
    "plt.plot(epochs, original_train_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, bigger_model_train_loss, 'bo', label = 'Bigger model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training losss가 0에 굉장히 빠르게 가까워지는 것을 확인할 수 있다. 네트워크가 더 많은 capacity를 가지면, training data를 모델링 할 수 있으므로(train loss가 적으므로) 빠른 모델링이 가능하지만, 과도하게 적용되면 위와 같이 training loss와 validation loss가 크게 다르게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding weight regularization\n",
    "\n",
    "overfitting을 완화하는 일반적인 방법은 가중치(cost가 작은 값을 가지도록 만들어서 네트워크의 complexity 에 제한점을 두는 것(to put constraints)이다. 이렇게 하면 가중치값의 분포를 조금 더 regular, 즉 정규화할수 있다. 이러한 방식을 가중치 정규화라 한다.\n",
    "- L1 regularization : 여기서 추가된 cost는 가중치 상관계수의 절대값에 비례한다.\n",
    "- L2 regularization : 여기서 추가된 cost는 가중치의 상관계수의 제곱에 피례한다.  (예를 들어 가중치의 L2 norm 이라고 불린다.) L2 정규화는 신경 네트워크의 맥락에서(in the context of neural networks), 체중 감량(weight decay)라고도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여기서는..\n",
    "L2 regularization을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "l2_model = models.Sequential()\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu', input_shape=(10000,)))\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l2(0.001) means that every coefficient in the weight matrix of the layer will add 0.001 * weight_coefficient_value to the total loss of the network. Note that because this penalty is only added at training time, the loss for this network will be much higher at training than at test time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l2_model 적용\n",
    "네트워크의 사이즈는 12 이면서, 'relu'가 적용된 l2_model을 loss는 'binary_crossentropy'로 해서 컴파일한 것을 fitting한 후의 결과룰 표시해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 15s 593us/step - loss: 0.4969 - acc: 0.8175 - val_loss: 0.3893 - val_acc: 0.8726\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 12s 499us/step - loss: 0.3182 - acc: 0.9036 - val_loss: 0.3337 - val_acc: 0.8898\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 10s 406us/step - loss: 0.2744 - acc: 0.9182 - val_loss: 0.3295 - val_acc: 0.8882\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 8s 312us/step - loss: 0.2523 - acc: 0.9271 - val_loss: 0.3517 - val_acc: 0.8772\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 11s 438us/step - loss: 0.2369 - acc: 0.9339 - val_loss: 0.3368 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 8s 338us/step - loss: 0.2278 - acc: 0.9367 - val_loss: 0.3670 - val_acc: 0.8732\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 10s 411us/step - loss: 0.2194 - acc: 0.9404 - val_loss: 0.3572 - val_acc: 0.8795\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 9s 359us/step - loss: 0.2167 - acc: 0.9399 - val_loss: 0.3619 - val_acc: 0.8780\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 11s 456us/step - loss: 0.2095 - acc: 0.9435 - val_loss: 0.3686 - val_acc: 0.8764\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 9s 370us/step - loss: 0.2069 - acc: 0.9448 - val_loss: 0.3853 - val_acc: 0.8718\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 9s 357us/step - loss: 0.2049 - acc: 0.9443 - val_loss: 0.3795 - val_acc: 0.8752\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 9s 353us/step - loss: 0.2024 - acc: 0.9451 - val_loss: 0.3883 - val_acc: 0.8731\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 6s 247us/step - loss: 0.1963 - acc: 0.9491 - val_loss: 0.3895 - val_acc: 0.8733\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 6s 257us/step - loss: 0.1941 - acc: 0.9496 - val_loss: 0.5069 - val_acc: 0.8377\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 6s 244us/step - loss: 0.1927 - acc: 0.9498 - val_loss: 0.3990 - val_acc: 0.8707\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 6s 256us/step - loss: 0.1916 - acc: 0.9499 - val_loss: 0.4646 - val_acc: 0.8524\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 7s 272us/step - loss: 0.1904 - acc: 0.9500 - val_loss: 0.4083 - val_acc: 0.8697\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 8s 304us/step - loss: 0.1819 - acc: 0.9547 - val_loss: 0.4408 - val_acc: 0.8613\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 10s 396us/step - loss: 0.1862 - acc: 0.9502 - val_loss: 0.4167 - val_acc: 0.8680\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 9s 341us/step - loss: 0.1793 - acc: 0.9559 - val_loss: 0.4349 - val_acc: 0.8635\n"
     ]
    }
   ],
   "source": [
    "l2_model_hist = l2_model.fit(x_train, y_train,\n",
    "                             epochs=20,\n",
    "                             batch_size=512,\n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmcFPW57/HPw4iOKO5oUIRBg8qw\nyqoxLrihHgOixmh4netAotGIoslxC54wxmuO8SZ6o0eTuBCSKy4Ro5KEJMaocDWYw4AjsoRFD+gY\nogMRkYzEAZ7zR9W0zdAz3T3d1dU9/X2/XvXqrurqroeip57+LfX7mbsjIiIC0CXuAEREpHgoKYiI\nSIKSgoiIJCgpiIhIgpKCiIgkKCmIiEiCkoKIiCQoKYiISIKSgoiIJOwWdwDZOuigg7yqqiruMERE\nSsqiRYs2uHuPdPuVXFKoqqqirq4u7jBEREqKma3LZD9VH4mISIKSgoiIJCgpiIhIQsm1KaTS3NxM\nQ0MDW7dujTsUKRGVlZX06tWLrl27xh2KSFHpFEmhoaGB7t27U1VVhZnFHY4UOXdn48aNNDQ00Ldv\n37jDESkqnaL6aOvWrRx44IFKCJIRM+PAAw9UyVJKTm1t9MfoFEkBUEKQrOj7IqXo1lujP0anSQoi\nIpI7JYU8aWhoYPz48fTr148jjzySqVOn8sknn6Tc969//SsXXnhh2s8855xz2LRpU4fiqa2t5fvf\n/36H3pupmTNnMmXKlJz3EZG21daCWbDAp8+jqkoq66SQr5Pq7px//vmcd955rF69mlWrVrFlyxam\nTZu2y77btm3j0EMPZfbs2Wk/d+7cuey33375CVJESlJtLbgHC3z6XEkhAvmqn3vhhReorKxk0qRJ\nAFRUVHD33XczY8YMmpqamDlzJuPGjePUU0/ltNNOY+3atQwcOBCApqYmLrroIqqrq5kwYQKjR49O\nDONRVVXFhg0bWLt2Lf379+eyyy5jwIABnHnmmXz88ccAPPjgg4wcOZIhQ4ZwwQUX0NTU1G6sNTU1\nXHnllRx33HEcccQRvPTSS0yePJn+/ftTU1OT2O+xxx5j0KBBDBw4kBtvvDGx/ac//SlHHXUUo0aN\n4pVXXklsb2xs5IILLmDkyJGMHDlyp9dEpHSUdVLIl2XLljF8+PCdtu2zzz707t2bNWvWALB48WJm\nz57NvHnzdtrv/vvvZ//992f58uXcdtttLFq0KOUxVq9ezVVXXcWyZcvYb7/9eOqppwA4//zzWbhw\nIa+//jr9+/fn4YcfThvvBx98wIIFC7j77rsZN24c1113HcuWLeONN96gvr6ev/71r9x444288MIL\n1NfXs3DhQp555hnWr1/P9OnTeeWVV3j55ZdZvnx54jOnTp3Kddddx8KFC3nqqaf46le/mtU5FJH0\npk+P/hid4j6FbNTW7lxCaKmnmz492u5eZ5xxBgcccMAu219++WWmTp0KwMCBAxk8eHDK9/ft25eh\nQ4cCMHz4cNauXQvA0qVLueWWW9i0aRNbtmxh7NixaWP5whe+gJkxaNAgDjnkEAYNGgTAgAEDWLt2\nLevWreOUU06hR49gQMWJEycyf/58gJ22f+lLX2LVqlUAPP/88zslic2bN7Nly5a0sYhI5grRJbUs\nk0LLiTX7tJ4uF9XV1bu0EWzevJm3336bz372syxevJi99torp2PsscceiecVFRWJ6qOamhqeeeYZ\nhgwZwsyZM3nppZcy/qwuXbrs9LldunRh27ZtHbrLd8eOHbz66qtUVlZm/V4RKR6qPsqD0047jaam\nJn7+858DsH37dr75zW9SU1NDt27d2n3vCSecwC9+8QsAli9fzhtvvJHVsT/66CN69uxJc3Mzs2bN\n6tg/oJVRo0Yxb948NmzYwPbt23nsscc4+eSTGT16NPPmzWPjxo00Nzfz5JNPJt5z5plncu+99ybW\n6+vr8xKLiBRWWSeFfNXPmRlPP/00Tz75JP369eOoo46isrKS7373u2nf+/Wvf53Gxkaqq6u55ZZb\nGDBgAPvuu2/Gx77tttsYPXo0J5xwAsccc0wu/4yEnj17cscddzBmzBiGDBnC8OHDGT9+PD179qS2\ntpbjjz+eE044gf79+yfec88991BXV8fgwYOprq7mxz/+cV5iEZHCMs9H/UkBjRgxwltPsrNixYqd\nLlClZPv27TQ3N1NZWcmbb77J6aefzsqVK9l9993jDq3TK+XvjZSm5OrrQjOzRe4+It1+ZdemUGya\nmpoYM2YMzc3NuDv333+/EoJIJ3XrrfElhUwpKcSse/fuml5URIpGWbcpiIhErdDDVORKJQURkQhF\n0Q0+SiopiIhIgpKCiEiBFGKYilwpKeTJ3nvvvcu2u+66i+rqagYPHsxpp53GunXrCh5XR4bQnjNn\nDnfccUfOxz7llFMib0SvqalJO+JsJvuIFEKxtiMkK8ukMGsWVFVBly7BY55uBN7FscceS11dHUuW\nLOHCCy/khhtuSPuebdu2RRNMhrZt28a4ceO46aabYo1DROJRdklh1iy4/HJYty5o8Fm3LliPIjGM\nGTMmMczFcccdR0NDQ8r9ampquOKKKxg9ejQ33HAD//jHP5g8eTKjRo3i2GOP5dlnnwXaH2Y7uaQy\ne/bsnYbBbtHWMNutj588Mc7QoUMTy5577sm8efPajO/jjz/m4osvpn///kyYMCExPlNrVVVV3Hzz\nzQwdOpQRI0awePFixo4dy5FHHpm4E9rduf766xk4cCCDBg3iiSeeSGyfMmUKRx99NKeffjrvv/9+\n4nMXLVrEySefzPDhwxk7dizr16/P7D9KRBIi7X1kZmcBPwQqgIfc/Y5Wr98NjAlXuwEHu3uks8pM\nmwatpxxoagq2T5wY3XEffvhhzj777DZfb2ho4E9/+hMVFRV861vf4tRTT2XGjBls2rSJUaNGcfrp\np/OjH/0oMcz20qVLE6OmZur888/nsssuA+CWW27h4Ycf5uqrr97l+DNnzky8p2UMo1/96lfceeed\nfO5zn2P69Okp4/vJT35Ct27dWLFiBUuWLGHYsGFtxtK7d2/q6+u57rrrqKmp4ZVXXmHr1q0MHDiQ\nK664gl/+8pfU19fz+uuvs2HDBkaOHMlJJ53EggULWLlyJcuXL+e9996jurqayZMn09zczNVXX82z\nzz5Ljx49eOKJJ5g2bRozZszI6hyJlLvIkoKZVQD3AWcADcBCM5vj7onxld39uqT9rwaOjSqeFm+/\nnd32fHjkkUeoq6vbZS6FZF/84hepqKgA4LnnnmPOnDmJtoCtW7fy9ttvZzzMdlvaG2Y7+fitrV69\nmuuvv54XX3yRrl27thnf/PnzueaaawAYPHhwu/GNGzcOgEGDBrFlyxa6d+9O9+7d2WOPPdi0aRMv\nv/wyl1xyCRUVFRxyyCGcfPLJLFy4kPnz5ye2H3rooZx66qkArFy5kqVLl3LGGWcAwfAhPXv2zOr8\niEi0JYVRwBp3fwvAzB4HxgPL29j/EiDytvnevYMqo1Tbo/D8889z++23M2/evMQw1dOmTeM3v/kN\n8Okv8eShtd2dp556iqOPPjrj41jLnTEEF+lU2htmu62hvbds2cJFF13Egw8+mLjIdiS+1tIN350t\nd2fAgAEsWLCgwzGJSLRtCocB7yStN4TbdmFmfYC+wAsRxgPA7bdD69Gsu3ULtufba6+9xte+9jXm\nzJnDwQcfnBTD7dTX17c5vPTYsWO59957aRms8LXXXgPaH2b7kEMOYcWKFezYsYOnn3465ed2ZJjt\nyZMnM2nSJE488cS08Z100kk8+uijQFAqWbJkSUbHSOXEE0/kiSeeYPv27TQ2NjJ//nxGjRrFSSed\nlNi+fv16XnzxRQCOPvpoGhsbE0mhubmZZcuWdfj4IuWqWO5ovhiY7e7bU71oZpcDl0NQF52LlnaD\nadOCKqPevYOEkGt7QlNTE7169Uqsf+Mb32Du3Lls2bKFL37xi0AQ+5w5c9J+1r//+79z7bXXMnjw\nYHbs2EHfvn359a9/zde//nUuvfRSqqurOeaYY3YaZvuOO+7g3HPPpUePHowYMSLlrGctw2z36NGD\n0aNH89FHH7Ubx7p165g9ezarVq1K1M0/9NBDbcZ35ZVXMmnSJPr370///v13maI0GxMmTGDBggUM\nGTIEM+POO+/kM5/5DBMmTOCFF16gurqa3r17c/zxxwOw++67M3v2bK655ho+/PBDtm3bxrXXXsuA\nAQM6HINIOYps6GwzOx6odfex4frNAO7+Hyn2fQ24yt3/lO5zO9vQ2dnQMNv5VS7fGxEojqGzFwL9\nzKwv8C5BaeDLrXcys2OA/QFVBqehYbZFJGqRJQV332ZmU4DfE3RJneHuy8zsO0Cdu7fUo1wMPO6l\nNttPDDTMtohELdI2BXefC8xtte3brdZr83SsnXrgiLRHv0FEUusUdzRXVlayceNG/aFLRtydjRs3\nUllZGXcoUmJKYeyiXHWKOZqbm5tpaGhos3++SGuVlZX06tWLrl27xh2KlJBSmA+hLcXQ0FwwXbt2\npW/fvnGHISJS8jpF9ZGISFRKbTrNXHWK6iMRkUIoh+ojlRRERCRBSUFEJEOlMJ1mrpQUREQy1Fnb\nEZIpKYiISIKSgoiIJCgpiIhIgpKCiIgkKCmIiEiCkoKIiCQoKYhI2SiHLqW5UlIQkbJx661xR1D8\nlBRERCRBSUFESkZHqn/KbZTTXGmUVBEpGbmOUlrKo5zmSqOkiohI1pQURKSo5bP6pxxGOc2Vqo9E\npGSUc/VPrlR9JCIiWVNSEJGSoeqf6CkpiEjJUDfS6CkpiIhIgpKCiIgkKCmIiEiCkoKIiCQoKYiI\nSIKSgoiIJCgpiIhIgpKCiIgkRJoUzOwsM1tpZmvM7KY29rnIzJab2TIzezTKeEREpH27RfXBZlYB\n3AecATQAC81sjrsvT9qnH3AzcIK7f2BmB0cVj4iIpBdlSWEUsMbd33L3T4DHgfGt9rkMuM/dPwBw\n9/cjjEdEcpTrMBMapqL4RZkUDgPeSVpvCLclOwo4ysxeMbNXzeysVB9kZpebWZ2Z1TU2NkYUroik\nk+vE97m+X6KXNimY2V5m1iV8fpSZjTOzrnk6/m5AP+AU4BLgQTPbr/VO7v6Au49w9xE9evTI06FF\nRKS1TEoK84FKMzsMeA74V2BmBu97Fzg8ab1XuC1ZAzDH3Zvd/b+BVQRJQkSKRK4zn+Vz5jSJXtqZ\n18xssbsPM7OrgT3d/U4zq3f3oWnetxvBRf40gmSwEPiyuy9L2ucs4BJ3v9TMDgJeA4a6+8a2Plcz\nr4nEJ9eZzzRzWnzyOfOamdnxwETgN+G2inRvcvdtwBTg98AK4BfuvszMvmNm48Ldfg9sNLPlwIvA\n9e0lBBERiVYmXVKvJeg2+nR4UT+C4AKelrvPBea22vbtpOcOfCNcRKTI5TrzmWZOK35pq4922jlo\ncN7b3TdHF1L7VH0kIpK9vFUfmdmjZraPme0FLAWWm9n1+QhSRESKSyZtCtVhyeA84LdAX4IeSCIi\n0slkkhS6hvclnEfYfRRQ/wERkU4ok6TwE2AtsBcw38z6ALG1KYiISHTS9j5y93uAe5I2rTOzMdGF\nJCIiccmkoXlfM7urZewhM/sBQalBREQ6mUyqj2YAHwEXhctm4KdRBiUiIvHI5Oa1I939gqT1W82s\nPqqAREQkPpmUFD42s8+3rJjZCcDH0YUkIiJxyaSkcCXwMzPbFzDg70BNlEGJiEg8Mul9VA8MMbN9\nwnV1RxUR6aTaTApmlnKQOgsHRXf3uyKKSUREYtJeSaF7waIQEZGi0GZScHfNpioiUmYy6X0kIp2E\npsCUdJQURMrIrSr/SxpKCiIikpDJ2Ed7mNmXzexbZvbtlqUQwYlI7mprwSxY4NPnqkqSVDK5ee1Z\n4ENgEfDPaMMRkXyrrf00AZhBFjPwShnKJCn0cvezIo9ERERil0mbwp/MbFDkkYhI5KZPjzsCKXaZ\nlBQ+D9SY2X8TVB8Z4O4+ONLIRCTv1I4g6WSSFM6OPAoRESkKaauP3H0dsB/whXDZL9wmIiKdTCZd\nUqcCs4CDw+URM7s66sBERKTwMqk++gow2t3/AWBm3wMWAPdGGZiIiBReJr2PDNietL493CYiIp1M\nJiWFnwJ/NrOnw/XzgIejC0lEROKSycxrd5nZSwRdUwEmuftrkUYlIiKxaLP6qGX6TTM7AFgLPBIu\n68JtIlImZs2Cqiro0iV4nDUr7ogkKu2VFB4FziUY8yh5tBQL14+IMC4RKRKzZsHll0NTU7C+bl2w\nDjBxYnxxSTTMS2x0rBEjRnhdXV3cYYiUjaqqIBG01qcPrF1b6Giko8xskbuPSLdfJvcp/DGTbW28\n9ywzW2lma8zsphSv15hZo5nVh8tXM/lcESmct9/ObruUtjarj8ysEugGHGRm+/NpN9R9gMPSfbCZ\nVQD3AWcADcBCM5vj7stb7fqEu0/pSPAiEr3evVOXFHr3LnwsEr32SgpfI2hPOCZ8bFmeBf4zg88e\nBaxx97fc/RPgcWB8buGKSKHdfjt067bztm7dgu3S+bSZFNz9h+7eF/g3dz/C3fuGyxB3zyQpHAa8\nk7TeQOoSxgVmtsTMZpvZ4ak+yMwuN7M6M6trbGzM4NAiki8TJ8IDDwRtCGbB4wMPqJG5s8qoodnM\nBgLVQGXLNnf/eZr3XAic5e5fDdf/lWC4jClJ+xwIbHH3f5rZ14Avufup7X2uGppFRLKXz4bm6QTj\nHN0LjAHuBMZlEMO7QPIv/17htgR33+juLVN8PgQMz+BzRcqW5kOQqGUy9tGFwGnA39x9EjAE2DeD\n9y0E+plZXzPbHbgYmJO8g5n1TFodB6zIKGqRMnXrrXFHIJ1dJmMffezuO8xsW3iX8/vsXAJIyd23\nmdkU4PdABTDD3ZeZ2XeAOnefA1xjZuOAbcDfgZqO/kNERCR3mZQU6sxsP+BBgt5HiwmGzk7L3ee6\n+1HufqS73x5u+3aYEHD3m919QNh4Pcbd/9LBf4dIp1VbGzTwWtgpvOW5qpIkClnd0WxmVcA+7r4k\nqoDSUUOzlDMzKLFBCKRIZNrQ3N7Na8Pae83dF3c0OBERKU7ttSn8IHysBEYArxPc1TwYqAOOjzY0\nEWlt+vS4I5DOrr2b18a4+xhgPTDM3Ue4+3DgWFp1LRWRwlA7gkQtk4bmo939jZYVd18K9I8uJBER\niUsmXVKXmNlDBBPsAEwEYmtoFhGR6GRSUpgELAOmhsvycJuISEFo5rfCyWSO5q3A3eEiIlJQmvmt\nsNqbo/kX4eMb4SimOy2FC1FEytm0aZ8mhBZNTcF2yb/2SgpTw8dzCxGIiEgqmvmtsNrrkro+fFyX\nailciCKdg7qTdkxbM7xp5rdotFd99JGZbU6xfGRmmwsZpEhnoBFOO0YzvxVWm9VH7t69kIGIiKTS\n0pg8bVpQZdS7d5AQ1MgcjUy6pAJgZgebWe+WJcqgRDoLjXCaHxMnwtq1sGNH8KiEEJ20o6SG8x38\nADiUYC6FPsAKdx8QfXi70iipUqo0wqnEKW/TcQK3AccBq9y9L8EsbK/mGJ9IydGveykHmSSFZnff\nCHQxsy7u/iLBqKkiZSXXhmKNcFq6yumO6kzGPtpkZnsD84FZZvY+8I9owxLpfFTSKE3ldkd1JiWF\n8cDHwHXA74A3gS9EGZRIsVBDsRTDHdWFLKm02dBsZvcBj7r7K9EdPntqaJa4qKG4PHXpkvr/3Szo\nDRW11iUVCO7TeOCB7Eoq+WhoXgV838zWmtmdZnZs5ocXEekc4r6jutAllfaGufihux8PnAxsBGaY\n2V/MbLqZHRVNOCLFSw3F5SnuO6oLPfZT2jaFcKyj77n7scAlwHnAimjCESleakcoTxMnBlU1ffoE\nVUZ9+mRfdZOLQpdU0iYFM9vNzL5gZrOA3wIrgfOjCUdEpPjEeUd1oUsqbXZJNbMzCEoG5wD/BTwO\nXO7u6o4qIlIghR77qb3eRy8AjwJPufsH0Rw+e+p9JCKSvZx7H7n7qe7+UDElBBGRUlRKd0Rnckez\niIh0UKndEZ3x0NkipU69hyQOxXBHdDaUFKRsaOYziUOpzTGtpCAinV6cdfpx3xGdLSUF6dQ0oJ20\n1OmvWxeMYdRSp1+oxBD3HdHZSjvzWk4fbnYW8EOgAnjI3e9oY78LgNnASHdvt7+puqRKR2lAu/JU\nVRUkgtb69AluRCuEWbPin2M6nzOvdTSACuA+4GygGrjEzKpT7NcdmAr8OapYRCRecVbfFEOdfinN\nMR1l9dEoYI27v+XunxDcET0+xX63Ad8DtkYYi4gGtItJ3NU3pVanH7cok8JhwDtJ6w3htgQzGwYc\n7u6/iTAOEUDtCHGJu0tmqdXpxy22hmYz6wLcBXwzg30vN7M6M6trbGyMPjgRyZu4q2/iHuW01ESZ\nFN4FDk9a7xVua9EdGAi8ZGZrgeOAOWa2S0OIuz/g7iPcfUSPHj2yDqSUbjEXiUK5d8kspTr9uEWZ\nFBYC/cysr5ntDlwMzGl50d0/dPeD3L3K3auAV4Fx6XofZSvu+kyRfMjloh7334Cqb0qMu0e2EAy7\nvQp4E5gWbvsOwcW/9b4vASPSfebw4cM9G336uAd/Cjsvffpk9TFSBKZPj+e4jzwSfF/MgsdHHin8\n8bt12/n7261b5nEUw99A3OdQ3IE6z+C6Hel9ClHI9j6FuCfdlk/V1ubW2BvHfQb5mjQ9F7n2s9ff\ngEAR3KdQLIqhPlMCpTj2UNw9ZyD3hlr9DUg2On1SUH1maYt7mIp89JzJtZE314u6/gYkK5nUMRXT\nkm2bgrvqM+M0fXrq+uyOtA9AvqNLL9f6+FzbA/L5GfobKG+oTUGKTa5tAqXYppCvcXeKYewcKW2Z\ntilo5jUpGXEMU5HrpOn5unFr4kQlASmMTt+mIMUj14t6R9sRcq3Tz+XGJzXySqlRUpC08nU3bBxj\nD+nGLZHsKClIu+K+qOYq7i6lGndHSo2SgrQr7osq5FZSiXswNtC4O1JalBSkXXFfVHMtqahOXyQ7\nSgrSrnxcVHP5pZ9rSUV1+iLZUVKQduV6Uc31l36uJRXV6YtkR0mhBMQ5Fn6uF9Vcf+nno6SiOn2R\nzCkpFLli6P2Ty0U111/6qv4RKayySgqlOEdvMfT+yUWuv/RV/SNSWGWVFEpx6Oa4e/8k60hSzccv\nfVX/iBROWSWFUlRMXSo7klT1S1+ktHT6pBD3ePy56gx16vqlL1I6yiIptIxCD58+L5WkkI9f2rn0\nXir1pCoi2Smr+RTiGI8/bvmcY7gcz59IZ6E5mlPo6NDNcd4nkKtS770kIoVVVpPsdKTKo/Uv7Zb7\nBKA06sbz2XspjkluRKSwyqqk0BH5+KUdZ0kjn72X1I4g0vkpKaSR6y/tuO9I7gy9l0SkcJQU0sj1\nl3bcdfq6T0BEsqGkkEauv7SL4Y5k3ScgIplSUkgj11/axXRHsohIOkoKGcjll7bq9EWklCgpREx1\n+iJSSsrqPoW4TJyoJCAipUElBRERSVBSKCO6+UxE0lFSKCOlOMmQiBRWpEnBzM4ys5VmtsbMbkrx\n+hVm9oaZ1ZvZy2ZWHWU8IiLSvsiSgplVAPcBZwPVwCUpLvqPuvsgdx8K3AncFVU85UrzIYhINqIs\nKYwC1rj7W+7+CfA4MD55B3ffnLS6F6DR+vOs1CcZEpHCijIpHAa8k7TeEG7biZldZWZvEpQUrokw\nnpzpQioinV3sDc3ufp+7HwncCNySah8zu9zM6sysrrGxsbABJom7oTbXpKT5EEQkncim4zSz44Fa\ndx8brt8M4O7/0cb+XYAP3H3f9j43l+k4cxX3dJRxH19ESlcxTMe5EOhnZn3NbHfgYmBO8g5m1i9p\n9V+A1RHG0yFqqBWRchJZUnD3bcAU4PfACuAX7r7MzL5jZuPC3aaY2TIzqwe+AVwaVTwdFXdDrZKS\niBRSZNVHUVH1UXzHF5HSVQzVR52OGmpFpLNTUshCrlU26j0kIsVO1UcFpOofEYmLqo9ERCRrSgoR\nU+8hESklqj4qIFUfiUhcVH0kIiJZU1IoIPUeEpFip6RQQGpHEJFip6QgIiIJSgoiIpKgpCAiIglK\nCiIikqCkICIiCSV385qZNQLr4o6jDQcBG+IOoh2KLzfFHh8Uf4yKLze5xNfH3Xuk26nkkkIxM7O6\nTO4YjIviy02xxwfFH6Piy00h4lP1kYiIJCgpiIhIgpJCfj0QdwBpKL7cFHt8UPwxKr7cRB6f2hRE\nRCRBJQUREUlQUsiSmR1uZi+a2XIzW2ZmU1Psc4qZfWhm9eHy7QLHuNbM3giPvcvkExa4x8zWmNkS\nMxtWwNiOTjov9Wa22cyubbVPwc+fmc0ws/fNbGnStgPM7A9mtjp83L+N914a7rPazC4tUGz/x8z+\nEv7/PW1m+7Xx3na/CxHHWGtm7yb9P57TxnvPMrOV4ffxpgLG90RSbGvNrL6N90Z6Dtu6psT2/XN3\nLVksQE9gWPi8O7AKqG61zynAr2OMcS1wUDuvnwP8FjDgOODPMcVZAfyNoP90rOcPOAkYBixN2nYn\ncFP4/CbgeynedwDwVvi4f/h8/wLEdiawW/j8e6liy+S7EHGMtcC/ZfAdeBM4AtgdeL3131NU8bV6\n/QfAt+M4h21dU+L6/qmkkCV3X+/ui8PnHwErgMPijSpr44Gfe+BVYD8z6xlDHKcBb7p77Dcjuvt8\n4O+tNo8HfhY+/xlwXoq3jgX+4O5/d/cPgD8AZ0Udm7s/5+7bwtVXgV75PGa22jh/mRgFrHH3t9z9\nE+BxgvOeV+3FZ2YGXAQ8lu/jZqKda0os3z8lhRyYWRVwLPDnFC8fb2avm9lvzWxAQQMDB54zs0Vm\ndnmK1w8D3klabyCexHYxbf8hxnn+Whzi7uvD538DDkmxTzGcy8kEJb9U0n0XojYlrOKa0Ub1RzGc\nvxOB99x9dRuvF+wctrqmxPL9U1LoIDPbG3gKuNbdN7d6eTFBlcgQ4F7gmQKH93l3HwacDVxlZicV\n+PhpmdnuwDjgyRQvx33+duFBWb3ouuqZ2TRgGzCrjV3i/C78CDgSGAqsJ6iiKUaX0H4poSDnsL1r\nSiG/f0oKHWBmXQn+82a5+y/Ol2l0AAADmklEQVRbv+7um919S/h8LtDVzA4qVHzu/m74+D7wNEER\nPdm7wOFJ673CbYV0NrDY3d9r/ULc5y/Jey3VauHj+yn2ie1cmlkNcC4wMbxo7CKD70Jk3P09d9/u\n7juAB9s4dqzfRTPbDTgfeKKtfQpxDtu4psTy/VNSyFJY//gwsMLd72pjn8+E+2FmowjO88YCxbeX\nmXVveU7QILm01W5zgP8V9kI6DvgwqZhaKG3+Oovz/LUyB2jpzXEp8GyKfX4PnGlm+4fVI2eG2yJl\nZmcBNwDj3L2pjX0y+S5EGWNyO9WENo69EOhnZn3D0uPFBOe9UE4H/uLuDaleLMQ5bOeaEs/3L6oW\n9c66AJ8nKMYtAerD5RzgCuCKcJ8pwDKCnhSvAp8rYHxHhMd9PYxhWrg9OT4D7iPo9fEGMKLA53Av\ngov8vknbYj1/BAlqPdBMUC/7FeBA4I/AauB54IBw3xHAQ0nvnQysCZdJBYptDUFdcst38MfhvocC\nc9v7LhTw/P2/8Pu1hOAC17N1jOH6OQQ9bt6MKsZU8YXbZ7Z875L2Leg5bOeaEsv3T3c0i4hIgqqP\nREQkQUlBREQSlBRERCRBSUFERBKUFEREJEFJQSRkZttt5xFc8zZip5lVJY/QKVKsdos7AJEi8rG7\nD407CJE4qaQgkkY4nv6d4Zj6/2Vmnw23V5nZC+GAb380s97h9kMsmOPg9XD5XPhRFWb2YDhm/nNm\ntme4/zXhWPpLzOzxmP6ZIoCSgkiyPVtVH30p6bUP3X0Q8J/A/w233Qv8zN0HEwxId0+4/R5gngcD\n+g0juBMWoB9wn7sPADYBF4TbbwKODT/niqj+cSKZ0B3NIiEz2+Lue6fYvhY41d3fCgcu+5u7H2hm\nGwiGbmgOt69394PMrBHo5e7/TPqMKoJx7/uF6zcCXd39f5vZ74AtBKPBPuPhYIAicVBJQSQz3sbz\nbPwz6fl2Pm3T+xeCsaiGAQvDkTtFYqGkIJKZLyU9Lgif/4lgVE+AicD/D5//EbgSwMwqzGzftj7U\nzLoAh7v7i8CNwL7ALqUVkULRLxKRT+1pO0/e/jt3b+mWur+ZLSH4tX9JuO1q4Kdmdj3QCEwKt08F\nHjCzrxCUCK4kGKEzlQrgkTBxGHCPu2/K279IJEtqUxBJI2xTGOHuG+KORSRqqj4SEZEElRRERCRB\nJQUREUlQUhARkQQlBRERSVBSEBGRBCUFERFJUFIQEZGE/wFoxVz9QmzPFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1240c1d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, l2_model_val_loss, 'bo', label='L2-regularized model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자세히 보면 +와 o이 만나는 지점이 조금더 먼 지점에서 교차하게 되는 것을 확인 가능하다. 위와 같은 L2 regularization외에도 L1 regularization의 예제는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.L1L2 at 0x10ae80ed0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "# L1 regularization\n",
    "regularizers.l1(0.001)\n",
    "\n",
    "\n",
    "# L1 and L2 regularization at the same time\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DROP OUT 은 포기..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
